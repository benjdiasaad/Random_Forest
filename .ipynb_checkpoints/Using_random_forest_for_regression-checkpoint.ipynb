{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BENJDIA Saad **Random Forest**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Importer les bibliothèques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Exécutez le code suivant pour importer les bibliothèques nécessaires: </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Importation du dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Exécutez la commande suivante pour importer l'ensemble de données: </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('petrol_consumption.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Pour obtenir une vue d'ensemble de ce à quoi ressemble l'ensemble de données, exécutez la commande suivante: </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Petrol_tax</th>\n",
       "      <th>Average_income</th>\n",
       "      <th>Paved_Highways</th>\n",
       "      <th>Population_Driver_licence(%)</th>\n",
       "      <th>Petrol_Consumption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.00</td>\n",
       "      <td>3571</td>\n",
       "      <td>1976</td>\n",
       "      <td>0.525</td>\n",
       "      <td>541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.00</td>\n",
       "      <td>4092</td>\n",
       "      <td>1250</td>\n",
       "      <td>0.572</td>\n",
       "      <td>524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.00</td>\n",
       "      <td>3865</td>\n",
       "      <td>1586</td>\n",
       "      <td>0.580</td>\n",
       "      <td>561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.50</td>\n",
       "      <td>4870</td>\n",
       "      <td>2351</td>\n",
       "      <td>0.529</td>\n",
       "      <td>414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.00</td>\n",
       "      <td>4399</td>\n",
       "      <td>431</td>\n",
       "      <td>0.544</td>\n",
       "      <td>410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10.00</td>\n",
       "      <td>5342</td>\n",
       "      <td>1333</td>\n",
       "      <td>0.571</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8.00</td>\n",
       "      <td>5319</td>\n",
       "      <td>11868</td>\n",
       "      <td>0.451</td>\n",
       "      <td>344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.00</td>\n",
       "      <td>5126</td>\n",
       "      <td>2138</td>\n",
       "      <td>0.553</td>\n",
       "      <td>467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8.00</td>\n",
       "      <td>4447</td>\n",
       "      <td>8577</td>\n",
       "      <td>0.529</td>\n",
       "      <td>464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7.00</td>\n",
       "      <td>4512</td>\n",
       "      <td>8507</td>\n",
       "      <td>0.552</td>\n",
       "      <td>498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>8.00</td>\n",
       "      <td>4391</td>\n",
       "      <td>5939</td>\n",
       "      <td>0.530</td>\n",
       "      <td>580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>7.50</td>\n",
       "      <td>5126</td>\n",
       "      <td>14186</td>\n",
       "      <td>0.525</td>\n",
       "      <td>471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7.00</td>\n",
       "      <td>4817</td>\n",
       "      <td>6930</td>\n",
       "      <td>0.574</td>\n",
       "      <td>525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>7.00</td>\n",
       "      <td>4207</td>\n",
       "      <td>6580</td>\n",
       "      <td>0.545</td>\n",
       "      <td>508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>7.00</td>\n",
       "      <td>4332</td>\n",
       "      <td>8159</td>\n",
       "      <td>0.608</td>\n",
       "      <td>566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7.00</td>\n",
       "      <td>4318</td>\n",
       "      <td>10340</td>\n",
       "      <td>0.586</td>\n",
       "      <td>635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>7.00</td>\n",
       "      <td>4206</td>\n",
       "      <td>8508</td>\n",
       "      <td>0.572</td>\n",
       "      <td>603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>7.00</td>\n",
       "      <td>3718</td>\n",
       "      <td>4725</td>\n",
       "      <td>0.540</td>\n",
       "      <td>714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>7.00</td>\n",
       "      <td>4716</td>\n",
       "      <td>5915</td>\n",
       "      <td>0.724</td>\n",
       "      <td>865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>8.50</td>\n",
       "      <td>4341</td>\n",
       "      <td>6010</td>\n",
       "      <td>0.677</td>\n",
       "      <td>640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>7.00</td>\n",
       "      <td>4593</td>\n",
       "      <td>7834</td>\n",
       "      <td>0.663</td>\n",
       "      <td>649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>8.00</td>\n",
       "      <td>4983</td>\n",
       "      <td>602</td>\n",
       "      <td>0.602</td>\n",
       "      <td>540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>9.00</td>\n",
       "      <td>4897</td>\n",
       "      <td>2449</td>\n",
       "      <td>0.511</td>\n",
       "      <td>464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>9.00</td>\n",
       "      <td>4258</td>\n",
       "      <td>4686</td>\n",
       "      <td>0.517</td>\n",
       "      <td>547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>8.50</td>\n",
       "      <td>4574</td>\n",
       "      <td>2619</td>\n",
       "      <td>0.551</td>\n",
       "      <td>460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>9.00</td>\n",
       "      <td>3721</td>\n",
       "      <td>4746</td>\n",
       "      <td>0.544</td>\n",
       "      <td>566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>8.00</td>\n",
       "      <td>3448</td>\n",
       "      <td>5399</td>\n",
       "      <td>0.548</td>\n",
       "      <td>577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>7.50</td>\n",
       "      <td>3846</td>\n",
       "      <td>9061</td>\n",
       "      <td>0.579</td>\n",
       "      <td>631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>8.00</td>\n",
       "      <td>4188</td>\n",
       "      <td>5975</td>\n",
       "      <td>0.563</td>\n",
       "      <td>574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>9.00</td>\n",
       "      <td>3601</td>\n",
       "      <td>4650</td>\n",
       "      <td>0.493</td>\n",
       "      <td>534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>7.00</td>\n",
       "      <td>3640</td>\n",
       "      <td>6905</td>\n",
       "      <td>0.518</td>\n",
       "      <td>571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>7.00</td>\n",
       "      <td>3333</td>\n",
       "      <td>6594</td>\n",
       "      <td>0.513</td>\n",
       "      <td>554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>8.00</td>\n",
       "      <td>3063</td>\n",
       "      <td>6524</td>\n",
       "      <td>0.578</td>\n",
       "      <td>577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>7.50</td>\n",
       "      <td>3357</td>\n",
       "      <td>4121</td>\n",
       "      <td>0.547</td>\n",
       "      <td>628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>8.00</td>\n",
       "      <td>3528</td>\n",
       "      <td>3495</td>\n",
       "      <td>0.487</td>\n",
       "      <td>487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>6.58</td>\n",
       "      <td>3802</td>\n",
       "      <td>7834</td>\n",
       "      <td>0.629</td>\n",
       "      <td>644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>5.00</td>\n",
       "      <td>4045</td>\n",
       "      <td>17782</td>\n",
       "      <td>0.566</td>\n",
       "      <td>640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>7.00</td>\n",
       "      <td>3897</td>\n",
       "      <td>6385</td>\n",
       "      <td>0.586</td>\n",
       "      <td>704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>8.50</td>\n",
       "      <td>3635</td>\n",
       "      <td>3274</td>\n",
       "      <td>0.663</td>\n",
       "      <td>648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>7.00</td>\n",
       "      <td>4345</td>\n",
       "      <td>3905</td>\n",
       "      <td>0.672</td>\n",
       "      <td>968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>7.00</td>\n",
       "      <td>4449</td>\n",
       "      <td>4639</td>\n",
       "      <td>0.626</td>\n",
       "      <td>587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>7.00</td>\n",
       "      <td>3656</td>\n",
       "      <td>3985</td>\n",
       "      <td>0.563</td>\n",
       "      <td>699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>7.00</td>\n",
       "      <td>4300</td>\n",
       "      <td>3635</td>\n",
       "      <td>0.603</td>\n",
       "      <td>632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>7.00</td>\n",
       "      <td>3745</td>\n",
       "      <td>2611</td>\n",
       "      <td>0.508</td>\n",
       "      <td>591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>6.00</td>\n",
       "      <td>5215</td>\n",
       "      <td>2302</td>\n",
       "      <td>0.672</td>\n",
       "      <td>782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>9.00</td>\n",
       "      <td>4476</td>\n",
       "      <td>3942</td>\n",
       "      <td>0.571</td>\n",
       "      <td>510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>7.00</td>\n",
       "      <td>4296</td>\n",
       "      <td>4083</td>\n",
       "      <td>0.623</td>\n",
       "      <td>610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>7.00</td>\n",
       "      <td>5002</td>\n",
       "      <td>9794</td>\n",
       "      <td>0.593</td>\n",
       "      <td>524</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Petrol_tax  Average_income  Paved_Highways  Population_Driver_licence(%)  \\\n",
       "0         9.00            3571            1976                         0.525   \n",
       "1         9.00            4092            1250                         0.572   \n",
       "2         9.00            3865            1586                         0.580   \n",
       "3         7.50            4870            2351                         0.529   \n",
       "4         8.00            4399             431                         0.544   \n",
       "5        10.00            5342            1333                         0.571   \n",
       "6         8.00            5319           11868                         0.451   \n",
       "7         8.00            5126            2138                         0.553   \n",
       "8         8.00            4447            8577                         0.529   \n",
       "9         7.00            4512            8507                         0.552   \n",
       "10        8.00            4391            5939                         0.530   \n",
       "11        7.50            5126           14186                         0.525   \n",
       "12        7.00            4817            6930                         0.574   \n",
       "13        7.00            4207            6580                         0.545   \n",
       "14        7.00            4332            8159                         0.608   \n",
       "15        7.00            4318           10340                         0.586   \n",
       "16        7.00            4206            8508                         0.572   \n",
       "17        7.00            3718            4725                         0.540   \n",
       "18        7.00            4716            5915                         0.724   \n",
       "19        8.50            4341            6010                         0.677   \n",
       "20        7.00            4593            7834                         0.663   \n",
       "21        8.00            4983             602                         0.602   \n",
       "22        9.00            4897            2449                         0.511   \n",
       "23        9.00            4258            4686                         0.517   \n",
       "24        8.50            4574            2619                         0.551   \n",
       "25        9.00            3721            4746                         0.544   \n",
       "26        8.00            3448            5399                         0.548   \n",
       "27        7.50            3846            9061                         0.579   \n",
       "28        8.00            4188            5975                         0.563   \n",
       "29        9.00            3601            4650                         0.493   \n",
       "30        7.00            3640            6905                         0.518   \n",
       "31        7.00            3333            6594                         0.513   \n",
       "32        8.00            3063            6524                         0.578   \n",
       "33        7.50            3357            4121                         0.547   \n",
       "34        8.00            3528            3495                         0.487   \n",
       "35        6.58            3802            7834                         0.629   \n",
       "36        5.00            4045           17782                         0.566   \n",
       "37        7.00            3897            6385                         0.586   \n",
       "38        8.50            3635            3274                         0.663   \n",
       "39        7.00            4345            3905                         0.672   \n",
       "40        7.00            4449            4639                         0.626   \n",
       "41        7.00            3656            3985                         0.563   \n",
       "42        7.00            4300            3635                         0.603   \n",
       "43        7.00            3745            2611                         0.508   \n",
       "44        6.00            5215            2302                         0.672   \n",
       "45        9.00            4476            3942                         0.571   \n",
       "46        7.00            4296            4083                         0.623   \n",
       "47        7.00            5002            9794                         0.593   \n",
       "\n",
       "    Petrol_Consumption  \n",
       "0                  541  \n",
       "1                  524  \n",
       "2                  561  \n",
       "3                  414  \n",
       "4                  410  \n",
       "5                  457  \n",
       "6                  344  \n",
       "7                  467  \n",
       "8                  464  \n",
       "9                  498  \n",
       "10                 580  \n",
       "11                 471  \n",
       "12                 525  \n",
       "13                 508  \n",
       "14                 566  \n",
       "15                 635  \n",
       "16                 603  \n",
       "17                 714  \n",
       "18                 865  \n",
       "19                 640  \n",
       "20                 649  \n",
       "21                 540  \n",
       "22                 464  \n",
       "23                 547  \n",
       "24                 460  \n",
       "25                 566  \n",
       "26                 577  \n",
       "27                 631  \n",
       "28                 574  \n",
       "29                 534  \n",
       "30                 571  \n",
       "31                 554  \n",
       "32                 577  \n",
       "33                 628  \n",
       "34                 487  \n",
       "35                 644  \n",
       "36                 640  \n",
       "37                 704  \n",
       "38                 648  \n",
       "39                 968  \n",
       "40                 587  \n",
       "41                 699  \n",
       "42                 632  \n",
       "43                 591  \n",
       "44                 782  \n",
       "45                 510  \n",
       "46                 610  \n",
       "47                 524  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Préparation des données pour la formation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align: justify;\"> Deux tâches seront effectuées dans cette section. La première tâche consiste à diviser les données en ensembles «features» et «target». Les données résultantes sont ensuite divisées en  training and test sets. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[:, 0:4].values\n",
    "y = dataset.iloc[:, 4].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Enfin, divisons les données en  training and test sets: </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Formation de l'algorithme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:justify;\"> Il est temps d'entraîner notre algorithme de <b> forêt aléatoire </b> pour résoudre ce problème de régression. Exécutez le code suivant: </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = RandomForestRegressor(n_estimators=200, random_state=0)\n",
    "regressor.fit(X_train, y_train)\n",
    "y_pred = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align=justify\"> La calsse RandomForestRegressor de la bibliothèque sklearn.ensemble permet de résoudre les problèmes de régression via une forêt aléatoire. Le paramètre le plus important de la classe RandomForestRegressor est le n_estimators paramètre. Ce paramètre définit le nombre d'arbres dans la forêt aléatoire. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Évaluation de l'algorithme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:justify\"> La dernière étape de la résolution d'un problème d'apprentissage automatique consiste à évaluer les performances de l'algorithme. Pour les problèmes de régression, les métriques utilisées pour évaluer un algorithme, l'erreur quadratique moyenne. Exécutez le code suivant pour rechercher ces valeurs: </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 4216.166749999999\n",
      "Root Mean Squared Error: 64.93201637097064\n"
     ]
    }
   ],
   "source": [
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align=justify\"> Avec 20 arbres, l'erreur quadratique moyenne est de 64,93, ce qui est supérieur à 10 pour cent de la consommation moyenne d'essence, soit 576,77. Cela peut indiquer, entre autres, que nous n'avons pas utilisé suffisamment d'estimateurs (arbres). </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5> Si le nombre d'estimateurs passe à 200, les résultats sont les suivants: </h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 3497.802072500001\n",
      "Root Mean Squared Error: 59.142219035981405\n"
     ]
    }
   ],
   "source": [
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Erreur quadratique moyenne\n",
    "<p style=\"text-align=justify\"> L'erreur quadratique moyenne (RMSE) est la racine carrée de la moyenne du carré de toutes les erreurs. L'utilisation de RMSE est très courante et elle est considérée comme une excellente métrique d'erreur à usage général pour les prédictions numériques. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"rmse.png\" style=\"width=60px height:60px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align=justify\"> <b> NB : </b> est une mesure fréquemment utilisée des différences entre les valeurs (valeurs d'échantillon ou de population) prédites par un modèle ou un estimateur et les valeurs observées, n le nombre d'observations disponibles pour l'analyse.</p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
